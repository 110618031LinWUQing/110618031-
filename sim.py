# -*- coding: utf-8 -*-
"""Copy of sim.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SJakbAb4ujejGMiz2HmBGeXLcsiIyXT9
"""

from google.colab import drive
drive.mount('/content/gdrive')

import numpy as np
import h5py
import glob
import os
import tensorflow.keras.optimizers
from sklearn.model_selection import train_test_split
from keras.utils import np_utils
import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import LearningRateScheduler,ModelCheckpoint,EarlyStopping
from keras.models import Sequential
from keras.layers import Dropout,Activation,Flatten,BatchNormalization
from keras.layers import MaxPool2D,Conv2D,MaxPooling2D,Dense
import cv2
from keras.applications.resnet import ResNet50
from keras.applications.vgg16 import VGG16
import matplotlib.pyplot as plt

dict_characters = {0:'abraham_grampa_simpson',1:'agnes_skinner',2:'apu_nahasapeemapetilon',3:'barney_gumble',4:'bart_simpson',5:'brandine_spuckler'
,6:'carl_carlson',7:'charles_montgomery_burns',8:'chief_wiggum',9:'cletus_spuckler',10:'comic_book_guy'
,11:'disco_stu',12:'dolph_starbeam',13:'duff_man',14:'edna_krabappel',15:'fat_tony'
,16:'gary_chalmers',17:'gil',18:'groundskeeper_willie',19:'homer_simpson',20:'jimbo_jones'
,21:'kearney_zzyzwicz',22:'kent_brockman',23:'krusty_the_clown',24:'lenny_leonard',25:'lionel_hutz'
,26:'lisa_simpson',27:'lunchlady_doris',28:'maggie_simpson',29:'marge_simpson',30:'martin_prince'
,31:'mayor_quimby',32:'milhouse_van_houten',33:'miss_hoover',34:'moe_szyslak',35:'ned_flanders'
,36:'nelson_muntz',37:'otto_mann',38:'patty_bouvier',39:'principal_skinner',40:'professor_john_frink'
,41:'rainier_wolfcastle',42:'ralph_wiggum',43:'selma_bouvier',44:'sideshow_bob',45:'sideshow_mel'
,46:'snake_jailbird',47:'timothy_lovejoy',48:'troy_mcclure',49:'waylon_smithers'}

img_width = 60
img_hight = 60
num_classes = len(dict_characters)
test_size = 0.15
img_path = '/content/gdrive/MyDrive/theSimpsons-train/train'

def laod_picture():
  pics = []
  labels = []

  for k,v in dict_characters.items(): #k:數字編碼  v:角色label
    pictures = [k for k in glob.glob(img_path + "/" + v + "/*")]   #把某一角色在檔案夾裡的所有圖像檔的路徑抓出來
    print(v + " : " + str(len(pictures)))
    for i,pic in enumerate(pictures):
      tmp_img = cv2.imread(pic)

      tmp_img = cv2.cvtColor(tmp_img,cv2.COLOR_BGR2RGB)
      tmp_img = cv2.resize(tmp_img, (img_hight,img_width))
      pics.append(tmp_img)
      labels.append(k)
  return np.array(pics),np.array(labels)

def get_dataset(save = False,load = False):
  if load :
    #從檔案系統中載入之前處理保存的訓練資料集與驗證資料集
    h5f = h5py.File('train.h5','r')
    X_train = h5f['X_train'][:]
    X_test = h5f['X_test'][:]
    h5f.close()
    #從檔案系統中載入之前處理保存的訓練資料標籤與驗證資料集
    h5f = h5py.File('valid.h5','r')
    y_train = h5f['y_train'][:]
    y_test = h5f['y_test'][:]
    h5f.close()
  else:
    #從最原始的圖像檔案開始處理
    X,y = laod_picture()
    y = keras.utils.np_utils.to_categorical(y, num_classes) #目標的類別種類數
    #將資料切分為訓練集與驗證集(85%/15%)
    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = test_size)
    if save: #保存尚未進行歸一化的圖像數據
      h5f = h5py.File('train.h5','w')
      h5f.create_dataset('X_train',data = X_train)
      h5f.create_dataset('X_test',data = X_test)
      h5f.close()

      h5f = h5py.File('vaild.h5','w')
      h5f.create_dataset('y_train',data = y_train)
      h5f.create_dataset('y_test',data = y_test)
      h5f.close()
#進行圖像每個像素值的型別轉換與歸一化處理
  X_train = X_train.astype('float32') / 255.
  X_test = X_test.astype('float32') / 255.
  print("Train",X_train.shape,y_train.shape)
  print("valid",X_test.shape,y_test.shape)
  
  return X_train,X_test,y_train,y_test

X_train,X_test,y_train,y_test = get_dataset(save = True,load = False)

#from keras.backend import flatten

additional_model = Sequential()
pretrained_res = ResNet50(weights='imagenet',include_top=False,input_shape=(img_hight,img_width,3))

additional_model.add(pretrained_res)
additional_model.add(Flatten())
additional_model.add(Dense(1024,activation='relu'))
additional_model.add(Dense(512,activation='relu'))
additional_model.add(Dense(50,activation='softmax'))

optimizer = 'Adam'
additional_model.compile(optimizer = optimizer,loss = 'categorical_crossentropy',metrics = ['accuracy'])

from urllib.parse import scheme_chars
model = additional_model
model.summary() #秀出模型架構
lr = 0.001
#配置一個常用的組合來作為後續優化的基準點
batch_size = 64
epochs = 12
def lr_schedule(epoch):
  return lr*(0.1**int(epochs/10))

datagen = ImageDataGenerator(shear_range=0.2,zoom_range=0.2,horizontal_flip=True)

history = model.fit(datagen.flow(X_train,y_train),batch_size = batch_size,epochs = epochs, validation_data = (X_test,y_test),shuffle = True,callbacks = [LearningRateScheduler(lr_schedule),
                                                                                        ModelCheckpoint('model.h5',
                                                                                        save_best_only = True, save_freq = 10),
                                                                                        EarlyStopping(monitor = "val_accuracy",
                                                                                        patience=3,mode= "auto")])

def plot_train_history(history,train_metrics,val_metrics):
  plt.plot(history.history.get(train_metrics),'-o')
  plt.plot(history.history.get(val_metrics),'-o')
  plt.xlabel('Epochs')
  plt.legend(['train','validation'])

plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plot_train_history(history,'loss','val_loss')

plt.subplot(1,2,2)
plot_train_history(history,'accuracy','val_accuracy')

plt.show()

from keras.applications import imagenet_utils
def read_images(path):
  images = []
  for i in range(10791):
    image = cv2.resize(cv2.imread(path+str(i+1)+".jpg"),(img_hight,img_width))
    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
    images.append(image)
  images = np.array(images,dtype = np.float32)/255
  return images

#model = load_model('model.h5')
img_path='/content/gdrive/MyDrive/theSimpsons-test/test/'
read_test_images = read_images(img_path)
predict = model.predict(read_test_images)
predict = np.argmax(predict,axis=1)

with open ('predict.csv','w') as f:
  f.write('id,character\n')
  for i in range(len(predict)):
    f.write(str(i+1)+","+dict_characters[((predict[i]))]+"\n")